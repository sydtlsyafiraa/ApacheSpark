{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cads-logo.png\" style=\"height: 100px;padding-top:5px\" align=left> <img src=\"images/apache_spark.png\" style=\"height: 20%;width:20%; padding-top:0px\" align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Data using Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to get our hands dirty with Spark DataFrame API to perform common data operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at dataset folder, you will see `flights.csv` that contains a row for every flight that left Portland International Airport (PDX) or Seattle-Tacoma International Airport (SEA) in 2014 and 2015.\n",
    "\n",
    "In the first step, we should create a DataFrame using `flights.csv` file and then create a table (temporaray view) for querying flights by using SQL commands. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MAIN_DIRECTORY = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Syaidatul Syafira\\\\OneDrive - studentupmedumy.onmicrosoft.com\\\\Desktop\\\\DA\\\\Big Data Analytics with Apache Spark\\\\Apache Spark SC'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAIN_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = MAIN_DIRECTORY+\"/dataset/flights.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_flights = spark.read.format(\"csv\").option(\"header\",\"true\").option('inferSchema','true').load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple way to create a dataframe in Spark\n",
    "df_flights = spark.read.csv(file_path, header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights.createOrReplaceTempView('flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use SQL to get the first five rows of the flights table and save the result to flights5, finally show the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights5 = spark.sql(\"SELECT * FROM flights LIMIT 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Write a query that counts the number of flights to each airport from SEA and PDX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+\n",
      "|origin|dest|count(1)|\n",
      "+------+----+--------+\n",
      "|   SEA| RNO|       8|\n",
      "|   SEA| DTW|      98|\n",
      "|   SEA| CLE|       2|\n",
      "|   SEA| LAX|     450|\n",
      "|   PDX| SEA|     144|\n",
      "|   SEA| BLI|       5|\n",
      "|   PDX| IAH|      57|\n",
      "|   PDX| PHX|     209|\n",
      "|   SEA| SLC|     225|\n",
      "|   SEA| SBA|      23|\n",
      "|   SEA| BWI|      29|\n",
      "|   PDX| IAD|      23|\n",
      "|   PDX| SFO|     305|\n",
      "|   SEA| KOA|      40|\n",
      "|   PDX| MCI|      15|\n",
      "|   SEA| SJC|     213|\n",
      "|   SEA| ABQ|      43|\n",
      "|   SEA| SAT|      18|\n",
      "|   PDX| ONT|      57|\n",
      "|   SEA| LAS|     364|\n",
      "+------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"SELECT origin, dest, count(*) FROM flights \\\n",
    "          GROUP BY origin, dest\").show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Write a piece of code to create a DataFrame using `airports.csv`, this file contains information about different airports all over the world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = MAIN_DIRECTORY + \"/dataset/airports.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports = spark.read.csv(file_path, header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+-----------+----+---+---+\n",
      "|faa|                name|       lat|        lon| alt| tz|dst|\n",
      "+---+--------------------+----------+-----------+----+---+---+\n",
      "|04G|   Lansdowne Airport|41.1304722|-80.6195833|1044| -5|  A|\n",
      "|06A|Moton Field Munic...|32.4605722|-85.6800278| 264| -5|  A|\n",
      "|06C| Schaumburg Regional|41.9893408|-88.1012428| 801| -6|  A|\n",
      "|06N|     Randall Airport| 41.431912|-74.3915611| 523| -5|  A|\n",
      "|09J|Jekyll Island Air...|31.0744722|-81.4277778|  11| -4|  A|\n",
      "+---+--------------------+----------+-----------+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airports.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at performing column-wise operations. In Apache Spark, you can do this using the `.withColumn(colName, col)`  which returns a new DataFrame by adding a column or replacing the existing column that has the same name.\n",
    "\n",
    "*Parameters*:  \n",
    "- **colName** – string, name of the new column.\n",
    "- **col** – a Column expression for the new column. \n",
    "\n",
    "The new `column` must be an object of class Column. Creating one of these is as easy as extracting a column from your DataFrame using `df.colName`.\n",
    "Apache Spark DataFrame is **immutable**. Immutable means that it can't be changed, and so columns can't be updated in place.\n",
    "For example:\n",
    "```python\n",
    "df = df.withColumn(\"newCol\", df.oldCol + 1)\n",
    "```\n",
    "The above code creates a DataFrame with the same columns as df plus a new column, `newCol`, where every entry is equal to the corresponding entry from `oldCol`, plus one.\n",
    "\n",
    "Sometimes we have to change a column data type to another one, in this case, we can use the following code:\n",
    "```python\n",
    "from pyspark.sql.functions import col\n",
    "df_name = df_name.withColumn(\"columnName\", col(\"columnName\").cast(\"DataType\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Update `flights` DataFrame to include a new column called `duration_hrs`, that contains the duration of each flight in hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = df_flights.withColumn(\"duration_hrs\", df_flights.air_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|      duration_hrs|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|               2.2|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|               6.0|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|              1.85|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|1.3833333333333333|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|2.1166666666666667|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Write a query using the `.filter()` method to find all the flights that flew over 1000 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"SELECT origin, dest, count(*) FROM flights \\\n",
    "    #      GROUP BY origin, dest\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|flight|distance|\n",
      "+------+--------+\n",
      "|   851|    2677|\n",
      "|   490|    1050|\n",
      "|    26|    1721|\n",
      "|   656|    1107|\n",
      "|   121|    1448|\n",
      "|   827|    1733|\n",
      "|    24|    2496|\n",
      "|   616|    2378|\n",
      "|    29|    2640|\n",
      "|   488|    1050|\n",
      "|   907|    1448|\n",
      "|   815|    2701|\n",
      "|    18|    2554|\n",
      "|  1598|    2182|\n",
      "|    99|    1448|\n",
      "|   794|    1180|\n",
      "|  1212|    1874|\n",
      "|   500|    1107|\n",
      "|  2164|    1426|\n",
      "|   593|    1107|\n",
      "+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.select('flight', 'distance').filter(df_flights['distance'] > 1000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights.select('flight', 'distance').filter(df_flights['distance'] > 1000).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Write a query using `.filter()` method, to only keep flights from SEA to PDX. This query should only return `tailnum`, `origin`, and `dest` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----+\n",
      "|tailnum|origin|dest|\n",
      "+-------+------+----+\n",
      "| N810SK|   SEA| PDX|\n",
      "| N822SK|   SEA| PDX|\n",
      "| N586SW|   SEA| PDX|\n",
      "| N223SW|   SEA| PDX|\n",
      "| N580SW|   SEA| PDX|\n",
      "+-------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution 1\n",
    "df_flights.select('tailnum', 'origin','dest').filter(df_flights.origin == 'SEA' ).filter(df_flights.dest == 'PDX').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform column-wise operations using `.select()` method. When we select a column using the `df.colName` notation. In `.select()` method, we can perform any column operation and it will return the transformed column. \n",
    "For example, the following command returns a column of flight durations in hours instead of minutes.\n",
    "```python\n",
    "df_flights.select(df_flights.air_time/60)\n",
    "```\n",
    "We can use the `alias()` method to rename a column we've selected. The following example shows how we can do that.\n",
    "```python\n",
    "df_flights.select((df_flights.air_time/60).alias(\"duration_hrs\")\n",
    "```\n",
    "If we want to stick to the SQL syntax, we can use `.selectExpr()` method as well. The following commad is equivalent to the previous code.\n",
    "\n",
    "```python\n",
    "df_flights.selectExpr(\"air_time/60 as duration_hrs\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Write a query that return these columns, `origin`, `dest`, `tailnum`, and average speed in KM per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+------------------+\n",
      "|origin|dest|tailnum| (distance / hour)|\n",
      "+------+----+-------+------------------+\n",
      "|   SEA| LAX| N846VA|             159.0|\n",
      "|   SEA| HNL| N559AS|             267.7|\n",
      "|   SEA| SFO| N847VA|              48.5|\n",
      "|   PDX| SJC| N360SW|33.470588235294116|\n",
      "|   SEA| BUR| N612AS|133.85714285714286|\n",
      "+------+----+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solution 1\n",
    "df_flights.select(\"origin\",\"dest\", \"tailnum\", (df_flights.distance / df_flights.hour)).alias(\"average_speed\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+----------------------------+\n",
      "|origin|dest|tailnum|(distance / (air_time / 60))|\n",
      "+------+----+-------+----------------------------+\n",
      "|   SEA| LAX| N846VA|           433.6363636363636|\n",
      "|   SEA| HNL| N559AS|           446.1666666666667|\n",
      "|   SEA| SFO| N847VA|          367.02702702702703|\n",
      "|   PDX| SJC| N360SW|           411.3253012048193|\n",
      "|   SEA| BUR| N612AS|           442.6771653543307|\n",
      "+------+----+-------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solution 1\n",
    "df_flights.select(\"origin\",\"dest\", \"tailnum\", (df_flights.distance / (df_flights.air_time/60))).alias(\"average_speed\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Find the the shortest (in terms of distance) flight that left PDX by first filtering and using the `.min()` method. Perform the filtering by referencing the column directly, not passing a SQL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|origin|min(distance)|\n",
      "+------+-------------+\n",
      "|   PDX|          106|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solution 1\n",
    "df_flights.filter(df_flights.origin == 'PDX' ).groupBy(df_flights.origin).agg({'distance':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solutin 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Find the the longest (in terms of time) flight that left SEA by filtering and using the `.max()` method. Perform the filtering by referencing the column directly, not passing a SQL string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we run the following code, we will get an error, because `air_time` data type is string, first we should cast it to an integer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      " |-- duration_hrs: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_flights = df_flights.withColumn(\"air_time\", col(\"air_time\").cast(\"integer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|origin|max(air_time)|\n",
      "+------+-------------+\n",
      "|   SEA|          409|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solution 1\n",
    "df_flights.filter(df_flights.origin == 'SEA' ).groupBy(df_flights.origin).agg({'air_time':'max'}).alias(\"Longest time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: Write a query that uses the `.avg()` method to get the average air time of Delta Airlines flights ( the carrier column value is \"DL\") that left SEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "|origin|carrier|     avg(air_time)|\n",
      "+------+-------+------------------+\n",
      "|   SEA|     DL|188.20689655172413|\n",
      "+------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solution 1\n",
    "df_flights.filter(df_flights.carrier == 'DL' ).filter(df_flights.origin ==\"SEA\").groupBy(\"origin\",\"carrier\").agg({'air_time':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11: Write a query that uses the `.sum()` method to get the total number of hours all planes spent in the air by creating a column called `duration_hrs` from the column `air_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| sum(duration_hrs)|\n",
      "+------------------+\n",
      "|25289.600000000126|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df_flights = df_flights.withColumn(\"duration_hrs\", df_flights.air_time/60).groupBy().sum(\"duration_hrs\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12: Write a query that uses `tailnum` column to count the number of flights each plane made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|tailnum|count(1)|\n",
      "+-------+--------+\n",
      "| N442AS|      38|\n",
      "| N102UW|       2|\n",
      "| N36472|       4|\n",
      "| N38451|       4|\n",
      "| N73283|       4|\n",
      "| N513UA|       2|\n",
      "| N954WN|       5|\n",
      "| N388DA|       3|\n",
      "| N567AA|       1|\n",
      "| N516UA|       2|\n",
      "| N927DN|       1|\n",
      "| N8322X|       1|\n",
      "| N466SW|       1|\n",
      "|  N6700|       1|\n",
      "| N607AS|      45|\n",
      "| N622SW|       4|\n",
      "| N584AS|      31|\n",
      "| N914WN|       4|\n",
      "| N654AW|       2|\n",
      "| N336NW|       1|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT tailnum, count(*) FROM flights \\\n",
    "            GROUP BY tailnum\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13: Write a query that returns the average duration of flights from `PDX` and `SEA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|origin|     avg(air_time)|\n",
      "+------+------------------+\n",
      "|   SEA| 160.4361496051259|\n",
      "|   PDX|137.11543248288737|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.groupBy('origin').avg('air_time').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14: Write a query that returns the average departure delay (`dep_delay`) in each month for each destination. Then import PySpark functions to calculate the standard deviation of `dep_delay` by using `stddev()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = df_flights.withColumn(\"dep_delay\", col(\"dep_delay\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: integer (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dest = df_flights.groupBy(\"month\",\"dest\").agg({'dep_delay':'avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------------------+\n",
      "|month|dest|    avg(dep_delay)|\n",
      "+-----+----+------------------+\n",
      "|    4| PHX|1.6833333333333333|\n",
      "|    1| RDM|            -1.625|\n",
      "|    5| ONT|3.5555555555555554|\n",
      "|    7| OMA|              -6.5|\n",
      "|    8| MDW|              7.45|\n",
      "+-----+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_dest.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------------------+\n",
      "|month|dest| stddev(dep_delay)|\n",
      "+-----+----+------------------+\n",
      "|    4| PHX|15.003380033491737|\n",
      "|    1| RDM| 8.830749846821778|\n",
      "|    5| ONT|18.895178691342874|\n",
      "|    7| OMA|2.1213203435596424|\n",
      "|    8| MDW|14.467659032985843|\n",
      "|    6| DEN|13.536905534420026|\n",
      "|    5| IAD|3.8078865529319543|\n",
      "|   12| COS|1.4142135623730951|\n",
      "|   11| ANC|18.604716401245316|\n",
      "|    5| AUS| 4.031128874149275|\n",
      "|    5| COS| 33.38163167571851|\n",
      "|    2| PSP| 4.878524367060187|\n",
      "|    4| ORD|11.593882803741764|\n",
      "|   10| DFW| 45.53019017606675|\n",
      "|   10| DCA|0.7071067811865476|\n",
      "|    8| JNU| 40.79368823727514|\n",
      "|   11| KOA|1.8708286933869707|\n",
      "|   10| OMA|5.8594652770823155|\n",
      "|    6| ONT| 25.98316762829351|\n",
      "|    3| MSP|21.556779370817555|\n",
      "+-----+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_dest = df_flights.groupBy(\"month\",\"dest\").agg({'dep_delay':'stddev'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15: Write a query that performs left outer join on the flights and airports DataFrames.\n",
    "- The flights and airports DataFrames are already in the workspace. \n",
    "- First, examine the airports DataFrame by calling .show() method. \n",
    "- Note which key column will let you join these two DataFrames.\n",
    "- Before joining these two DataFrames, rename the `faa` column in `airports` to `dest`, and then convert this DataFrame to a temporary view (table).\n",
    "- Use `spark.sql` to perform left outer join on these two tables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faa', 'name', 'lat', 'lon', 'alt', 'tz', 'dst']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'dep_time',\n",
       " 'dep_delay',\n",
       " 'arr_time',\n",
       " 'arr_delay',\n",
       " 'carrier',\n",
       " 'tailnum',\n",
       " 'flight',\n",
       " 'origin',\n",
       " 'dest',\n",
       " 'air_time',\n",
       " 'distance',\n",
       " 'hour',\n",
       " 'minute']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports = df_airports.withColumnRenamed('faa', 'dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dest', 'name', 'lat', 'lon', 'alt', 'tz', 'dst']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+----+--------------------+---------+-----------+----+---+---+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|dest|                name|      lat|        lon| alt| tz|dst|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+----+--------------------+---------+-----------+----+---+---+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58| LAX|    Los Angeles Intl|33.942536|-118.408075| 126| -8|  A|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40| HNL|       Honolulu Intl|21.318681|-157.922428|  13|-10|  N|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43| SFO|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5| SJC|Norman Y Mineta S...|  37.3626|-121.929022|  62| -8|  A|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54| BUR|            Bob Hope|34.200667|-118.358667| 778| -8|  A|\n",
      "|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37| DEN|         Denver Intl|39.861656|-104.673178|5431| -7|  A|\n",
      "|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47| OAK|Metropolitan Oakl...|37.721278|-122.220722|   9| -8|  A|\n",
      "|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55| SFO|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36| SAN|      San Diego Intl|32.733556|-117.189667|  17| -8|  A|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12| ORD|  Chicago Ohare Intl|41.978603| -87.904842| 668| -6|  A|\n",
      "|2014|   11|  8|    1653|       -2|    1924|       -1|     AS| N323AS|   448|   SEA| LAX|     130|     954|  16|    53| LAX|    Los Angeles Intl|33.942536|-118.408075| 126| -8|  A|\n",
      "|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA| PHX|     154|    1107|  11|    20| PHX|Phoenix Sky Harbo...|33.434278|-112.011583|1135| -7|  N|\n",
      "|2014|   10| 30|     811|       21|    1038|       29|     AS| N433AS|   608|   SEA| LAS|     127|     867|   8|    11| LAS|      Mc Carran Intl|36.080056| -115.15225|2141| -8|  A|\n",
      "|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA| ANC|     183|    1448|  23|    46| ANC|Ted Stevens Ancho...|61.174361|-149.996361| 152| -9|  A|\n",
      "|2014|   10| 31|    1314|       89|    1544|      111|     AS| N713AS|   306|   SEA| SFO|     129|     679|  13|    14| SFO|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "|2014|    1| 29|    2009|        3|    2159|        9|     UA| N27205|  1458|   PDX| SFO|      90|     550|  20|     9| SFO|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "|2014|   12| 17|    2015|       50|    2150|       41|     AS| N626AS|   368|   SEA| SMF|      76|     605|  20|    15| SMF|     Sacramento Intl|38.695417|-121.590778|  27| -8|  A|\n",
      "|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA| MDW|     216|    1733|  10|    17| MDW| Chicago Midway Intl|41.785972| -87.752417| 620| -6|  A|\n",
      "|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA| BOS|     290|    2496|  21|    56| BOS|General Edward La...|42.364347| -71.005181|  19| -5|  A|\n",
      "|2014|    6|  5|    1733|      -12|    1945|      -10|     OO| N215AG|  3488|   PDX| BUR|     111|     817|  17|    33| BUR|            Bob Hope|34.200667|-118.358667| 778| -8|  A|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+----+--------------------+---------+-----------+----+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"SELECT * \\\n",
    "                     FROM flights \\\n",
    "                     LEFT OUTER JOIN airports \\\n",
    "                     ON flights.dest = airports.dest\")\n",
    "df_join.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 16: Rewrite the previous query by using DataFrame API `.join` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PySpark, we can use `.join` method to perform joins. This method takes three arguments. \n",
    "- The first argument is the second DataFrame that we want to join with the first one. \n",
    "- The second argument, `on`, is the name of the key column(s) as a string. The names of the key column(s) must be the same in each table. \n",
    "- The third argument, `how`, specifies the kind of join to perform. \n",
    "\n",
    "To perform left outer join set the value of `how` to `\"leftouter\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_join = df_flights.join(df_airports, on='dest', how='leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+--------+--------+----+------+--------------------+---------+-----------+---+---+---+\n",
      "|dest|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|air_time|distance|hour|minute|                name|      lat|        lon|alt| tz|dst|\n",
      "+----+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+--------+--------+----+------+--------------------+---------+-----------+---+---+---+\n",
      "| LAX|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA|     132|     954|   6|    58|    Los Angeles Intl|33.942536|-118.408075|126| -8|  A|\n",
      "| HNL|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA|     360|    2677|  10|    40|       Honolulu Intl|21.318681|-157.922428| 13|-10|  N|\n",
      "| SFO|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA|     111|     679|  14|    43|  San Francisco Intl|37.618972|-122.374889| 13| -8|  A|\n",
      "| SJC|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX|      83|     569|  17|     5|Norman Y Mineta S...|  37.3626|-121.929022| 62| -8|  A|\n",
      "| BUR|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA|     127|     937|   7|    54|            Bob Hope|34.200667|-118.358667|778| -8|  A|\n",
      "+----+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+--------+--------+----+------+--------------------+---------+-----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awesome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
